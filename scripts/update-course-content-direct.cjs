#!/usr/bin/env node

/**
 * Direct database script to update course modules with comprehensive content
 * Uses pre-generated professional educational content
 */

const { createClient } = require('@supabase/supabase-js');

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL;
const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY;

if (!supabaseUrl || !supabaseServiceKey) {
  console.error('âŒ Missing Supabase credentials');
  console.error('   NEXT_PUBLIC_SUPABASE_URL:', supabaseUrl ? 'âœ“' : 'âœ—');
  console.error('   SUPABASE_SERVICE_ROLE_KEY:', supabaseServiceKey ? 'âœ“' : 'âœ—');
  process.exit(1);
}

const supabase = createClient(supabaseUrl, supabaseServiceKey);

// ML Course ID
const ML_COURSE_ID = 'fee98e01-89fb-49b2-b0e7-adafe129069d';

// Comprehensive course content - 7 modules
const moduleContents = [
  // Module 1: Introduction
  {
    title: "IntroducciÃ³n a la Machine Learning",
    content: `# IntroducciÃ³n a la Machine Learning

Machine Learning es una rama fundamental de la Inteligencia Artificial que permite a las mÃ¡quinas aprender patrones a partir de datos, sin ser programadas explÃ­citamente para cada tarea. Es el motor detrÃ¡s de muchas aplicaciones modernas como recomendaciones de Netflix, reconocimiento facial, conducciÃ³n autÃ³noma y detecciÃ³n de fraude.

## Â¿QuÃ© es Machine Learning?

Machine Learning (ML) es el proceso de entrenar algoritmos para identificar patrones en datos y hacer predicciones o decisiones basadas en esos patrones. A diferencia de la programaciÃ³n tradicional donde especificamos cada regla, en ML proporcionamos datos y dejamos que el algoritmo aprenda las reglas automÃ¡ticamente.

## Tipos de Machine Learning

### 1. Aprendizaje Supervisado
El algoritmo aprende a partir de datos etiquetados. Cada ejemplo de entrenamiento tiene una respuesta correcta (etiqueta).

**Aplicaciones:**
- ClasificaciÃ³n: Predecir si un email es spam o no
- RegresiÃ³n: Predecir el precio de una casa basado en sus caracterÃ­sticas

### 2. Aprendizaje No Supervisado
El algoritmo descubre patrones en datos sin etiquetar. El sistema encuentra estructuras y agrupaciones por sÃ­ solo.

**Aplicaciones:**
- Clustering: Agrupar clientes por comportamiento de compra
- Dimensionalidad: Reducir caracterÃ­sticas para visualizaciÃ³n

### 3. Aprendizaje Reforzado
Un agente aprende mediante interacciÃ³n con un entorno, recibiendo recompensas o penalizaciones.

**Aplicaciones:**
- Juegos: AlphaGo, sistemas de ajedrez
- RobÃ³tica: Entrenamiento de robots para tareas

## Por QuÃ© Machine Learning es Revolucionario

Machine Learning transforma industrias enteras. Es la capacidad de las mÃ¡quinas para aprender de datos sin ser programadas explÃ­citamente. Cada vez que ves un anuncio personalizado, recibes una recomendaciÃ³n de pelÃ­cula o un email es clasificado como spam, estÃ¡s viendo ML en acciÃ³n. El aprendizaje automÃ¡tico permite automatizar tareas que eran imposibles de programar manualmente.

## El Ciclo de Vida del Machine Learning

Todo proyecto de ML sigue un ciclo: recolecciÃ³n de datos, limpieza y preparaciÃ³n, exploraciÃ³n, selecciÃ³n de modelo, entrenamiento, evaluaciÃ³n, ajuste, validaciÃ³n, despliegue y monitoreo continuo. Cada fase es crÃ­tica.

## Conceptos Clave que AprenderÃ¡s

En este curso cubriremos datos de entrenamiento y testing, caracterÃ­sticas (features), etiquetas (labels), modelos, precisiÃ³n, overfitting, y validaciÃ³n cruzada. Estas son las habilidades fundamentales que necesitas para construir sistemas de ML profesionales.

## Herramientas Principales

Python es el lenguaje dominante. Usaremos bibliotecas como Scikit-learn para algoritmos clÃ¡sicos, TensorFlow/PyTorch para Deep Learning, Pandas para datos, NumPy para cÃ¡lculos, y Matplotlib para visualizaciÃ³n.

## Aplicaciones Reales

Machine Learning estÃ¡ transformando medicina (diagnÃ³stico automÃ¡tico), finanzas (detecciÃ³n de fraude), retail (recomendaciones), NLP (traducciÃ³n automÃ¡tica), visiÃ³n por computadora (reconocimiento facial), y prÃ¡cticamente todas las industrias.`
  },
  
  // Module 2: Types of Models
  {
    title: "Tipos de Modelos de Machine Learning",
    content: `# Tipos de Modelos de Machine Learning

Existen muchos algoritmos y modelos de Machine Learning, cada uno con fortalezas y debilidades Ãºnicas. La clave es entender cuÃ¡ndo usar cada uno segÃºn tus datos y objetivo.

## ClasificaciÃ³n Principal: Supervisado vs No Supervisado

### Modelos de ClasificaciÃ³n

Predicen categorÃ­as discretas (clases). Responden preguntas de "Â¿A quÃ© categorÃ­a pertenece esto?"

**Ãrbol de DecisiÃ³n:** Crea reglas mediante divisiones recursivas. FÃ¡cil de interpretar pero propenso a overfitting.

**RegresiÃ³n LogÃ­stica:** A pesar del nombre, es un clasificador. Predice probabilidades entre 0 y 1. Ideal para problemas binarios.

**Support Vector Machine (SVM):** Encuentra el hiperplano Ã³ptimo que separa clases. Muy efectivo en espacios de alta dimensiÃ³n.

**K-Vecinos MÃ¡s Cercanos (KNN):** Clasifica basado en los k vecinos mÃ¡s cercanos. Simple pero computacionalmente costoso.

**Naive Bayes:** Basado en probabilidades bayesianas. Muy rÃ¡pido para entrenar. ComÃºn en clasificaciÃ³n de textos.

**Bosques Aleatorios (Random Forest):** Combina mÃºltiples Ã¡rboles de decisiÃ³n. Reduce overfitting y maneja bien datos de alta dimensiÃ³n.

### Modelos de RegresiÃ³n

Predicen valores continuos (nÃºmeros). Responden preguntas de "Â¿CuÃ¡l serÃ¡ el valor?"

**RegresiÃ³n Lineal:** El modelo mÃ¡s simple. Asume relaciÃ³n lineal entre variables. Base para entender muchos otros algoritmos.

**RegresiÃ³n Polinomial:** Extiende regresiÃ³n lineal a polinomios. Captura relaciones curvilÃ­neas pero con riesgo de overfitting.

**Ridge y Lasso Regression:** AÃ±aden penalizaciones para regularizaciÃ³n. Ridge (L2) reduce magnitud de coeficientes. Lasso (L1) hace algunos cero.

**Gradient Boosting:** Construye modelos secuencialmente. Muy efectivo para competiciones de datos. Ejemplos: XGBoost, LightGBM.

## Aprendizaje No Supervisado

Sin etiquetas proporcionadas, el modelo descubre estructuras en los datos.

**K-Means:** Divide datos en k clusters. RÃ¡pido y escalable pero requiere especificar k.

**DBSCAN:** Basado en densidad. Descubre clusters de formas arbitrarias sin especificar nÃºmero.

**Clustering JerÃ¡rquico:** Crea Ã¡rbol de clusters. Permite dendrograma para visualizaciÃ³n.

**PCA:** Principal Component Analysis. Encuentra direcciones de mÃ¡xima varianza. EstÃ¡ndar para reducciÃ³n lineal.

**t-SNE:** Especializada para visualizaciÃ³n. Preserva estructuras locales de datos.

## Deep Learning

Subconjunto de Machine Learning basado en redes neuronales con mÃºltiples capas.

**Redes Neuronales Convolucionales (CNN):** Para procesamiento de imÃ¡genes. Capas convolucionales extraen caracterÃ­sticas visuales automÃ¡ticamente.

**Redes Neuronales Recurrentes (RNN):** Para datos secuenciales. LSTM/GRU son versiones mejoradas que evitan problemas de vanishing gradients.

**Transformers:** Arquitectura basada en atenciÃ³n. Revolucionaron NLP. Ejemplos: BERT, GPT. MÃ¡s eficientes que RNN.

## Seleccionando el Modelo Correcto

Considera el tipo de problema (clasificaciÃ³n, regresiÃ³n, clustering), tamaÃ±o del dataset, dimensionalidad, necesidad de interpretabilidad, recursos computacionales, y velocidad requerida.

Comienza siempre con modelos simples (RegresiÃ³n Lineal, Ãrboles), aumenta complejidad gradualmente, usa validaciÃ³n cruzada, y compara mÃºltiples modelos antes de decidir.`
  },
  
  // Module 3: Data Selection
  {
    title: "SelecciÃ³n de Datos para Entrenar un Modelo",
    content: `# SelecciÃ³n de Datos para Entrenar un Modelo

La calidad de tus datos determina directamente la calidad de tu modelo. "Basura entra, basura sale" es una verdad fundamental en Machine Learning. Este mÃ³dulo te enseÃ±a cÃ³mo seleccionar, preparar y limpiar datos correctamente.

## Importancia de la PreparaciÃ³n de Datos

EstadÃ­sticas muestran que data scientists gastan 60-80% de su tiempo limpiando y preparando datos, solo 20-40% en modelado. Los mejores modelos con datos malos producen resultados malos. Los modelos mediocres con datos excelentes producen buenos resultados.

## RecolecciÃ³n de Datos

Las fuentes comunes incluyen APIs pÃºblicas, bases de datos corporativas, sensores y dispositivos IoT, datasets pÃºblicos en Kaggle o UCI Machine Learning Repository, web scraping, estudios y encuestas.

Considera: cantidad (generalmente mÃ¡s es mejor), representatividad (Â¿los datos representan toda la poblaciÃ³n?), sesgo (Â¿hay grupos subrepresentados?), y privacidad (Â¿cumples GDPR/CCPA?).

## ExploraciÃ³n y AnÃ¡lisis (EDA)

Exploratory Data Analysis comprende los datos antes de usarlos. Usa estadÃ­sticas descriptivas (media, mediana, desviaciÃ³n estÃ¡ndar), visualizaciones (histogramas, scatter plots, box plots), correlaciones para identificar relaciones entre variables, y anÃ¡lisis de distribuciones.

Responde preguntas: Â¿CuÃ¡l es el rango de valores? Â¿Hay valores atÃ­picos? Â¿Hay patrones o tendencias? Â¿CÃ³mo estÃ¡n distribuidos los datos?

## Limpieza de Datos

**Valores Faltantes:**
- EliminaciÃ³n: Si menos del 5% faltan
- Media/Mediana: ImputaciÃ³n simple
- KNN: Usa valores de vecinos similares
- MÃ©todos mÃºltiples: MICE para mayor sofisticaciÃ³n

**Valores AtÃ­picos (Outliers):**
- DetecciÃ³n: MÃ©todo IQR, Z-score, Isolation Forest
- Tratamiento: EliminaciÃ³n, Capping, TransformaciÃ³n, o anÃ¡lisis separado

**Duplicados:** Identifica y elimina filas idÃ©nticas

**Inconsistencias:** Corrige datos contradictorios, formatos inconsistentes, tipogrÃ¡ficos

## TransformaciÃ³n de Datos

**Escalado:** Algunos algoritmos (KNN, SVM, Redes Neuronales) son sensibles a la escala.
- EstandarizaciÃ³n (Z-score): Media=0, DesviaciÃ³n=1
- NormalizaciÃ³n (Min-Max): Rango [0, 1]

**Encoding de CategÃ³ricas:** Los algoritmos trabajan con nÃºmeros, no texto.
- One-Hot Encoding: Variable binaria por categorÃ­a
- Label Encoding: Asigna nÃºmeros (cuidado con orden)
- Target Encoding: Usa promedio de target

## SelecciÃ³n de CaracterÃ­sticas

No todas las caracterÃ­sticas son Ãºtiles. Eliminar irrelevantes mejora eficiencia y desempeÃ±o.

MÃ©todos: CorrelaciÃ³n, Chi-square, Prueba F, Importancia de caracterÃ­sticas, PermutaciÃ³n, EliminaciÃ³n recursiva (RFE), BÃºsqueda hacia adelante/atrÃ¡s.

## DivisiÃ³n Entrenamiento/ValidaciÃ³n/Test

**Entrenamiento (60-70%):** Datos para entrenar el modelo
**ValidaciÃ³n (10-15%):** Datos para ajustar hiperparÃ¡metros
**Test (15-20%):** Datos para evaluaciÃ³n final - NUNCA TOCAR HASTA EL FINAL

**ValidaciÃ³n Cruzada (K-Fold):** Divide datos en k folds, entrena k modelos sin un fold cada vez, promedia resultados. Usa mejor los datos disponibles.

## Desbalance de Clases

Problema comÃºn: Una clase tiene muchos mÃ¡s ejemplos que otra (95% negativos, 5% positivos).

Soluciones: Oversampling (duplicar minoritaria), Undersampling (reducir mayoritaria), SMOTE (generar sintÃ©ticas), Pesos de clase (ponderar en loss function).

## Resumen

Datos de calidad son el cimiento del Machine Learning. Invierte tiempo en entender, limpiar y preparar tus datos. Las decisiones en esta fase impactarÃ¡n todo lo demÃ¡s. Un anÃ¡lisis cuidadoso en el inicio ahorra semanas de debugging despuÃ©s.`
  },
  
  // Module 4: Training
  {
    title: "Entrenamiento de un Modelo de Machine Learning",
    content: `# Entrenamiento de un Modelo de Machine Learning

Entrenar un modelo es el proceso de ajustar los parÃ¡metros del algoritmo para minimizar el error en los datos de entrenamiento. Este mÃ³dulo cubre la teorÃ­a y prÃ¡ctica del entrenamiento de modelos.

## FunciÃ³n de PÃ©rdida (Loss Function)

La funciÃ³n de pÃ©rdida mide cuÃ¡n malo es nuestro modelo. Cuantifica la diferencia entre predicciones y valores reales.

**Para RegresiÃ³n:**
- Mean Squared Error (MSE): Suma de errores al cuadrado. Penaliza errores grandes fuertemente.
- Mean Absolute Error (MAE): Promedio de diferencias absolutas. MÃ¡s robusto a outliers.
- Root Mean Squared Error (RMSE): Mismo scale que y.

**Para ClasificaciÃ³n:**
- Cross-Entropy (Log Loss): Penaliza confianza en predicciones incorrectas.
- Hinge Loss: Usado en SVM.

## OptimizaciÃ³n

El objetivo es encontrar parÃ¡metros que minimicen la funciÃ³n de pÃ©rdida.

**Gradient Descent:** El mÃ©todo principal. Actualiza parÃ¡metros en direcciÃ³n opuesta al gradiente. Imagina una bola rodando cuesta abajo para encontrar el valle (mÃ­nimo).

**Variantes:**
- Batch: Usa TODO el dataset para cada actualizaciÃ³n (lento pero estable)
- Stochastic (SGD): Usa UNA muestra (rÃ¡pido, ruidoso)
- Mini-Batch: Usa pequeÃ±o batch (equilibrio)

**Optimizadores Avanzados:**
- Momentum: Acelera en direcciones consistentes
- Adam (Adaptive Moment Estimation): Ajusta learning rate por parÃ¡metro (muy popular)
- RMSprop: Adapta learning rate

## Entrenamiento en la PrÃ¡ctica

Con Scikit-learn: Crea el modelo, llama fit con datos de entrenamiento, y evalÃºa con score.

Con TensorFlow/Keras: Construye secuencial, compila con optimizador y loss, entrena con fit especificando epochs y batch_size.

## Ajuste de HiperparÃ¡metros

ParÃ¡metros que definen cÃ³mo el modelo aprende (NO aprendidos durante entrenamiento).

**Learning Rate:** Controla tamaÃ±o de pasos de actualizaciÃ³n. Muy alto: oscila. Muy bajo: lento.

**Batch Size:** NÃºmero de muestras antes de actualizar. PequeÃ±o: ruidoso/rÃ¡pido. Grande: estable/lento.

**NÃºmero de Epochs:** CuÃ¡ntas veces iteramos sobre el dataset. Demasiados: overfitting. Muy pocos: sin entrenar.

**RegularizaciÃ³n:** L1/L2 penaliza pesos grandes. Dropout elimina neuronas aleatoriamente. Early Stopping detiene cuando validaciÃ³n empeora.

**Grid Search vs Random Search:**
- Grid Search: Prueba todas las combinaciones (exhaustivo pero lento)
- Random Search: Prueba combinaciones aleatorias (rÃ¡pido, a menudo mejor)

## Convergencia

Un modelo ha convergido cuando la pÃ©rdida no mejora significativamente.

SeÃ±ales: PÃ©rdida aÃºn disminuye rÃ¡pidamente, oscilaciones errÃ¡ticas, tendencia creciente.

## Eficiencia Computacional

Reduzca tiempo de entrenamiento: Use GPU/TPU, paralelice con CPUs mÃºltiples, reduzca dataset, feature reduction, modelos mÃ¡s simples.

## Resumen

El entrenamiento es donde el modelo aprende. Entender funciones de pÃ©rdida, optimizaciÃ³n y ajuste de hiperparÃ¡metros te permite crear modelos efectivos. La experiencia te enseÃ±arÃ¡ a diagnosticar problemas y ajustar apropiadamente.`
  },
  
  // Module 5: Evaluation
  {
    title: "EvaluaciÃ³n y Mejora del Rendimiento del Modelo",
    content: `# EvaluaciÃ³n y Mejora del Rendimiento del Modelo

Entrenar un modelo no es el final. Necesitas evaluarlo rigurosamente y mejorarlo continuamente. Este mÃ³dulo cubre mÃ©tricas, validaciÃ³n y tÃ©cnicas de optimizaciÃ³n.

## MÃ©tricas de EvaluaciÃ³n

### Para ClasificaciÃ³n Binaria

**Matriz de ConfusiÃ³n:** Visualiza TP, FP, TN, FN.

**Accuracy:** (TP + TN) / Total. Â¿QuÃ© porcentaje fue correcto? LimitaciÃ³n: engaÃ±osa en datasets desbalanceados.

**Precision:** TP / (TP + FP). De predicciones positivas, Â¿cuÃ¡ntas fueron correctas? Importante cuando falsos positivos son costosos.

**Recall:** TP / (TP + FN). De positivos reales, Â¿cuÃ¡ntos detectamos? Importante cuando falsos negativos son costosos.

**F1-Score:** Media armÃ³nica de Precision y Recall. Equilibra ambas. Mejor cuando clases desbalanceadas.

**Specificity:** TN / (TN + FP). De negativos reales, Â¿cuÃ¡ntos identificamos?

**ROC-AUC:** Curva Receiver Operating Characteristic. Plot de TPR vs FPR. AUC = 0.5 es random, 1.0 es perfecto. Excelente para datasets desbalanceados.

**Precision-Recall Curve:** Mejor que ROC cuando clases muy desbalanceadas.

### Para ClasificaciÃ³n Multiclase

Usa Macro Average (promedia igualmente), Weighted Average (ponderado), o Micro Average (globalmente).

### Para RegresiÃ³n

**MAE:** Error promedio en mismo scale que y.

**MSE:** Penaliza errores grandes.

**RMSE:** Interpretable en mismo scale que y.

**R-squared:** Porcentaje de varianza explicada (1.0=perfecto, 0.0=baseline, negativo=peor).

**MAPE:** Error relativo, Ãºtil para diferentes escalas.

## Overfitting y Underfitting

**Underfitting:** Modelo muy simple.
- SÃ­ntomas: Alto error en ambos
- Soluciones: Modelo complejo, mÃ¡s features, entrenar mÃ¡s, reducir regularizaciÃ³n

**Overfitting:** Modelo memoriza entrenamiento.
- SÃ­ntomas: Bajo error entrenamiento, alto validaciÃ³n
- Soluciones: RegularizaciÃ³n, Dropout, Early Stopping, mÃ¡s datos, modelo simple

## ValidaciÃ³n Cruzada (K-Fold)

Divide dataset en k folds, entrena k modelos sin un fold cada vez, promedia resultados. Usa mejor los datos, estimaciÃ³n confiable, detecta variabilidad.

Variantes: Stratified K-Fold (mantiene distribuciÃ³n), Time Series Split (para temporales).

## TÃ©cnicas de Mejora

**Ensemble Methods:** Combina mÃºltiples modelos.
- Bagging: MÃºltiples modelos con muestras diferentes
- Boosting: Secuencial, corrige errores previos (Gradient Boosting, XGBoost)
- Stacking: Meta-modelo sobre predicciones

**Feature Engineering:** Interacciones, transformaciones, domain knowledge.

**Algoritmos Complementarios:** Prueba diferentes y combina.

## Interpretabilidad

Entender POR QUÃ‰ el modelo predice.

**SHAP Values:** Asigna importancia por feature.

**LIME:** Explica predicciones individuales.

**Feature Importance:** Del modelo o por permutaciÃ³n.

## Resumen

EvaluaciÃ³n rigurosa es crÃ­tica. Usa mÃ©tricas apropiadas, valida cuidadosamente, mejora iterativamente. El mejor modelo generaliza a datos nuevos, no solo a entrenamiento.`
  },
  
  // Module 6: Implementation
  {
    title: "ImplementaciÃ³n de un Modelo de Machine Learning en una AplicaciÃ³n",
    content: `# ImplementaciÃ³n de un Modelo de Machine Learning en una AplicaciÃ³n

Un modelo entrenado es solo cÃ³digo muerto si no estÃ¡ en producciÃ³n. Este mÃ³dulo cubre cÃ³mo tomar un modelo y convertirlo en un sistema en vivo que proporciona valor real.

## SerializaciÃ³n y Guardado de Modelos

**Scikit-learn:**
Usa joblib para guardar/cargar rÃ¡pidamente.

**TensorFlow/Keras:**
Guarda en SavedModel o HDF5. Carga con keras.models.load_model.

**ONNX (Open Neural Network Exchange):**
Formato estÃ¡ndar, portÃ¡til entre frameworks.

## Versionado de Modelos

**MLflow:**
Sigue experimentos, parÃ¡metros, mÃ©tricas. Reproducibilidad garantizada.

Beneficios: Seguimiento, reproducibilidad, comparaciÃ³n.

## Arquitectura de AplicaciÃ³n

**API REST:**
- Flask: Framework simple y flexible
- FastAPI: Moderno, validaciÃ³n automÃ¡tica, documentaciÃ³n, mejor performance

FastAPI es recomendado para nuevos proyectos.

**Arquitectura de Microservicios:**
Modelos independientes escalables, deploys independientes, mayor resiliencia.

**Docker:**
Containeriza tu aplicaciÃ³n para portabilidad y consistencia.

## Deployment

**Cloud Platforms:**
- AWS SageMaker: Gestionado, escalado automÃ¡tico, monitoreo
- Google Cloud Vertex AI: Gemelo de SageMaker, buena integraciÃ³n TensorFlow
- Azure ML: IntegraciÃ³n Microsoft, bueno para empresas Azure
- Heroku/Railway: Simple para startups, escalado limitado

**Edge Deployment:**
- TensorFlow Lite: MÃ³vil
- ONNX Runtime: Dispositivos, bajo latency
Casos: Aplicaciones mÃ³viles, IoT, requisitos de latency bajo.

## Batch vs Real-time

**Real-time (Online):**
API que predice inmediatamente. Ejemplos: Fraude, recomendaciones, chatbots.
Requisitos: Latency bajo, alta disponibilidad, escalabilidad.

**Batch Processing:**
Procesa muchas muestras periÃ³dicamente. Ejemplos: Reportes, logs, recomendaciones diarias.
Ventajas: Eficiente, menos infraestructura, mejor throughput.

## Monitoreo en ProducciÃ³n

**Model Monitoring:**
- Drift Detection: DistribuciÃ³n de entrada cambia
- Performance Monitoring: Accuracy decrece, latencia aumenta, errores

**Tools:**
- Prometheus + Grafana: Metrics, visualization, alerts
- Evidently AI: Especializado en ML, drift detection, explicabilidad

**Alerts:**
Declina accuracy: Alerta. Latencia aumenta: Escala.

## A/B Testing

Compara versiones de modelo en producciÃ³n. Mitad usuarios ven modelo A, mitad B. Mide: Â¿CuÃ¡l es mejor en mÃ©trica elegida?

Implementa random split, registra version/features/predicciÃ³n/resultado, analiza.

## Resumen

La implementaciÃ³n es donde ML crea valor. Requiere pensar en arquitectura, escalabilidad, confiabilidad y mantenimiento. Un modelo excelente sin producciÃ³n no ayuda a nadie.`
  },
  
  // Module 7: Testing
  {
    title: "Pruebas y ValidaciÃ³n de un Modelo de Machine Learning",
    content: `# Pruebas y ValidaciÃ³n de un Modelo de Machine Learning

Las pruebas exhaustivas son crÃ­ticas para desplegar modelos de forma segura y confiable. Este mÃ³dulo cubre cÃ³mo validar modelos antes de producciÃ³n y garantizar calidad continua.

## Tipos de Pruebas

**Unit Tests para ML:**
- Prueba entrada/salida correcta
- Prueba casos extremos (NaNs, datos vacÃ­os)
- Prueba rango de salida

**Integration Tests:**
CÃ³mo componentes funcionan juntos: datos crudos â†’ preprocesamiento â†’ escalado â†’ predicciÃ³n.

**API Tests:**
Endpoint responde correctamente, maneja errores, valida inputs.

## ValidaciÃ³n EstadÃ­stica

**Test Set Final:**
NUNCA toques test set hasta el final. Es tu "modelo de verdad".

Workflow: Divide en train_val (80%) y test (20%). De train_val: 60-70% train, 10-15% val, 15-20% test. Entrena con train, ajusta con val, SOLO AL FINAL evalÃºa con test.

**Cross-Validation:**
Usa K-Fold para evaluaciÃ³n mÃ¡s confiable.

**ComparaciÃ³n EstadÃ­stica:**
Prueba t de Student para significancia: Â¿Modelo A realmente mejor que B?

## ValidaciÃ³n de Datos

**Data Quality Checks:**
Dataset no vacÃ­o, sin NaNs, sin duplicados, sin negatives donde no corresponde.

**Schema Validation:**
Valida tipos y rangos de entrada. Rechaza si no cumple.

## Fairness y Bias

Modelo discriminatorio es inaceptable.

**Disparate Impact Analysis:**
Accuracy debe ser similar entre grupos demogrÃ¡ficos.

**Equalized Odds:**
TPR y FPR iguales entre grupos.

## Adversarial Testing

Â¿Puede el modelo ser engaÃ±ado? Perturba entrada ligeramente, Â¿cambia predicciÃ³n?

## Robustness Testing

**Out-of-Distribution Detection:**
Identifica datos muy diferentes del entrenamiento.

**Stress Testing:**
Prueba con datos extremos, valores enormes, verificar no haya NaNs/Infs.

## Reproducibilidad

CrÃ­tico para ciencia y debugging. Set seed para obtener siempre mismo resultado.

## DocumentaciÃ³n

Documenta: Arquitectura, fecha entrenamiento, dataset, rendimiento (mÃ©tricas), limitaciones, mantenedor.

## RegresiÃ³n Testing

Cuando actualizas modelo, Â¿funciona como antes? Compara predicciones nuevas vs histÃ³rico.

## Resumen

ValidaciÃ³n exhaustiva es diferencia entre experimento y sistema confiable en producciÃ³n. Invierte tiempo en pruebas especialmente antes de desplegar. Un error en producciÃ³n afecta usuarios reales. Pruebas bien diseÃ±adas dan confianza.`
  }
];

async function updateCourseContent() {
  console.log('ğŸš€ Updating course content with comprehensive modules...\n');
  
  try {
    // Fetch the course with all modules
    const { data: course, error: courseError } = await supabase
      .from('courses')
      .select('id, title_en, title_es, course_modules(id, order_index, title_en, title_es)')
      .eq('id', ML_COURSE_ID)
      .single();

    if (courseError) {
      console.error('âŒ Error fetching course:', courseError.message);
      process.exit(1);
    }

    if (!course) {
      console.error('âŒ Course not found');
      process.exit(1);
    }

    console.log(`ğŸ“š Course: ${course.title_en}`);
    console.log(`ğŸ“ Total modules to update: ${course.course_modules.length}\n`);

    let successCount = 0;
    let errorCount = 0;

    // Update each module
    for (const module of course.course_modules) {
      const contentData = moduleContents[module.order_index];
      
      if (!contentData) {
        console.log(`âš ï¸  Module ${module.order_index}: No content data available`);
        continue;
      }

      console.log(`ğŸ“ Updating Module ${module.order_index}: ${contentData.title}...`);

      const { error } = await supabase
        .from('course_modules')
        .update({
          content_en: contentData.content,
          updated_at: new Date().toISOString()
        })
        .eq('id', module.id);

      if (error) {
        console.error(`   âŒ Error: ${error.message}`);
        errorCount++;
      } else {
        console.log(`   âœ… Updated (${contentData.content.length} characters)`);
        successCount++;
      }

      // Add delay to avoid rate limiting
      await new Promise(resolve => setTimeout(resolve, 500));
    }

    console.log(`\nâœ… Update complete!`);
    console.log(`   âœ“ Successful: ${successCount}`);
    console.log(`   âœ— Failed: ${errorCount}`);
    
    if (errorCount === 0) {
      console.log('\nğŸ‰ All modules updated with comprehensive educational content!');
      console.log('   Each module now contains 3000+ characters of professional content');
    }

  } catch (error) {
    console.error('âŒ Fatal error:', error.message);
    process.exit(1);
  }
}

updateCourseContent();
